{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:53715\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [03/Dec/2022 16:21:44] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [03/Dec/2022 16:21:44] \"GET /static/style.css HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [03/Dec/2022 16:21:44] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-03 16:21:46.734438: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "127.0.0.1 - - [03/Dec/2022 16:21:46] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.1651407e-05 1.3213247e-06 4.8463778e-07 1.1893407e-07 8.1770249e-06\n",
      " 1.0409408e-07 7.6661047e-07 1.2377746e-04 7.9036397e-07 1.4257852e-05\n",
      " 3.9663655e-06 7.8536635e-07 7.1298501e-07 1.0633505e-06 4.6595167e-05\n",
      " 5.1433723e-05 9.9875641e-01 1.4912644e-06 1.9698833e-05 3.5121229e-05\n",
      " 1.2936509e-07 4.8689642e-05 9.9173294e-06 5.0743543e-05 1.0032707e-05\n",
      " 8.4062558e-05 8.7608396e-07 3.1078656e-05 9.7479119e-07 1.8432862e-05\n",
      " 9.7988077e-06 2.4050460e-05 3.9294900e-05 8.6834643e-06 5.0162105e-04\n",
      " 5.3833555e-05 1.9057195e-05]\n",
      "[{'intent': 'greeting', 'probability': '0.9987564'}]\n",
      "greeting\n",
      "can i submit wes\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Dec/2022 16:21:57] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.55996646e-09 9.17189524e-09 2.63807004e-10 2.02011408e-09\n",
      " 2.60418683e-12 1.98342436e-11 1.69538198e-13 5.64581881e-10\n",
      " 9.44762704e-08 1.06120176e-07 1.63560632e-09 1.63411715e-10\n",
      " 1.73069031e-10 6.83167611e-09 4.37634462e-09 3.21874150e-09\n",
      " 2.71040967e-09 4.85198860e-12 2.04853925e-10 5.44249890e-09\n",
      " 1.67492075e-07 1.59179470e-09 1.51238009e-08 2.09185018e-13\n",
      " 2.88519236e-10 9.75266889e-09 2.38023556e-09 2.99034686e-10\n",
      " 9.81173406e-11 4.12248541e-10 7.55732277e-09 3.31960265e-10\n",
      " 8.40396364e-11 6.79750423e-10 4.13457532e-11 8.03691247e-09\n",
      " 9.99999642e-01]\n",
      "[{'intent': 'wes', 'probability': '0.99999964'}]\n",
      "wes\n",
      "argentina wonnnnnn\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Dec/2022 16:22:03] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.46908768e-04 6.09509480e-05 1.15004121e-04 6.67159256e-05\n",
      " 2.58596090e-04 2.97391744e-05 6.36760305e-05 2.66899145e-03\n",
      " 6.75965784e-05 1.52199878e-04 3.70801630e-04 8.72710661e-05\n",
      " 1.18899465e-04 1.30275075e-04 3.17623769e-03 8.71454924e-03\n",
      " 9.16591048e-01 1.04819417e-04 7.50531617e-04 9.25463508e-04\n",
      " 1.50212854e-05 2.35312013e-03 2.47786054e-04 2.90682958e-03\n",
      " 4.41492797e-04 2.81742611e-03 7.19098898e-05 2.45106057e-03\n",
      " 3.19007930e-04 5.89159143e-04 5.78315696e-04 1.86685345e-03\n",
      " 9.40358732e-04 3.02573346e-04 4.70437370e-02 1.14295969e-03\n",
      " 8.12069047e-04]\n",
      "[{'intent': 'failed', 'probability': '1'}]\n",
      "failed\n",
      "hellouuuuu\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Dec/2022 16:22:06] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.46908768e-04 6.09509480e-05 1.15004121e-04 6.67159256e-05\n",
      " 2.58596090e-04 2.97391744e-05 6.36760305e-05 2.66899145e-03\n",
      " 6.75965784e-05 1.52199878e-04 3.70801630e-04 8.72710661e-05\n",
      " 1.18899465e-04 1.30275075e-04 3.17623769e-03 8.71454924e-03\n",
      " 9.16591048e-01 1.04819417e-04 7.50531617e-04 9.25463508e-04\n",
      " 1.50212854e-05 2.35312013e-03 2.47786054e-04 2.90682958e-03\n",
      " 4.41492797e-04 2.81742611e-03 7.19098898e-05 2.45106057e-03\n",
      " 3.19007930e-04 5.89159143e-04 5.78315696e-04 1.86685345e-03\n",
      " 9.40358732e-04 3.02573346e-04 4.70437370e-02 1.14295969e-03\n",
      " 8.12069047e-04]\n",
      "[{'intent': 'failed', 'probability': '1'}]\n",
      "failed\n",
      "my name is nikita\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [03/Dec/2022 16:22:17] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.8737970e-04 1.6448919e-04 3.9577702e-04 2.8201472e-04 1.0243540e-01\n",
      " 8.2982320e-04 3.3515103e-03 7.0024985e-03 1.3348885e-03 4.6245050e-01\n",
      " 8.0082379e-04 2.3643796e-03 2.3793388e-04 1.0596115e-02 4.9832324e-03\n",
      " 8.0312032e-04 1.0427099e-01 1.1231845e-03 8.2463082e-03 7.0450653e-04\n",
      " 1.8721379e-02 6.8905936e-03 1.7567861e-03 1.1045182e-03 4.0251637e-04\n",
      " 4.3668557e-02 1.3099926e-03 4.5065422e-04 2.1984329e-04 4.7893482e-03\n",
      " 8.1538968e-03 4.6355939e-03 3.5645671e-02 3.6012180e-04 6.3834077e-04\n",
      " 1.4846669e-01 9.4206147e-03]\n",
      "[{'intent': 'failed', 'probability': '1'}]\n",
      "failed\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from flask import Flask, render_template, request\n",
    "import nltk\n",
    "from keras.models import load_model\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# chat initialization\n",
    "model = load_model(\"model_output/chatbot_model.h5\")\n",
    "intents = json.loads(open(\"data/intents.json\").read())\n",
    "words = pickle.load(open(\"model_output/words.pkl\", \"rb\"))\n",
    "classes = pickle.load(open(\"model_output/classes.pkl\", \"rb\"))\n",
    "\n",
    "app = Flask(__name__)\n",
    "# run_with_ngrok(app) \n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get\", methods=[\"POST\"])\n",
    "def chatbot_response():\n",
    "    msg = request.form[\"msg\"].lower()\n",
    "    print(msg)\n",
    "    # if msg.startswith('hi'):\n",
    "    #     name = msg[2:]\n",
    "    #     ints = predict_class(msg, model)\n",
    "    #     res1 = getResponse(ints, intents)\n",
    "    #     res =res1.replace(\"{n}\",name)\n",
    "    # elif msg.startswith('hi my name is'):\n",
    "    #     name = msg[14:]\n",
    "    #     ints = predict_class(msg, model)\n",
    "    #     res1 = getResponse(ints, intents)\n",
    "    #     res =res1.replace(\"{n}\",name)\n",
    "    # else:\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res\n",
    "\n",
    "\n",
    "# chat functionalities\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(\"found in bag: %s\" % w)\n",
    "    return np.array(bag)\n",
    "\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    print(res)\n",
    "\n",
    "    ERROR_THRESHOLD = 0.7\n",
    "\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    #sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    confidence_probability=0.95\n",
    "    return_list = []\n",
    "\n",
    "    if len(results) == 0:\n",
    "        return_list.append({\"intent\": 'failed', \"probability\": '1'})\n",
    "    elif results[0][1] >=  confidence_probability:\n",
    "        return_list.append({\"intent\": classes[results[0][0]], \"probability\": str(results[0][1])})\n",
    "    else: \n",
    "        return_list.append({\"intent\": 'failed', \"probability\": '1'})\n",
    "   \n",
    "    print(return_list)\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0][\"intent\"]\n",
    "    print(tag)\n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "\n",
    "    for i in list_of_intents:\n",
    "        if i[\"tag\"] == tag:\n",
    "            result = random.choice(i[\"responses\"])\n",
    "            break\n",
    "        else:\n",
    "            result= \"Sorry, I don't understand that. Please rephrase/ask another question or send an email to gradanalytics@georgetown.edu\"\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port='0000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987564"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=[[16, 0.9987564]]\n",
    "results[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "170ce1dd6f4b41f87201bcaa71a63fa2dc3233be29ef0b52e1889288dbb460d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
