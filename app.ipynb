{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:55501\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [05/Dec/2022 11:44:08] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [05/Dec/2022 11:44:08] \"GET /static/style.css HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Dec/2022 11:44:08] \"GET /style.css HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [05/Dec/2022 11:44:08] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 11:44:10.685262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "127.0.0.1 - - [05/Dec/2022 11:44:10] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 0.80256796]]\n",
      "[{'intent': 'greeting', 'probability': '0.80256796'}]\n",
      "greeting\n",
      "Answer:  Hi there, how can I help?\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "hi\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Dec/2022 11:44:14] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 0.80256796]]\n",
      "[{'intent': 'greeting', 'probability': '0.80256796'}]\n",
      "greeting\n",
      "Answer:  Hi there, how can I help?\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "how can i submit wes\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Dec/2022 11:44:20] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35, 0.9058166]]\n",
      "[{'intent': 'wes', 'probability': '0.9058166'}]\n",
      "wes\n",
      "Answer:  International applicants who attended institutions outside of the United States must submit WES. You will not need to send your WES report to our school at this time; instead, you should ask WES to send the evaluation directly to you, and then you should upload the evaluation directly to the online application. An official transcript will be required if you are offered admission to the program.\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "i wish to speak with someone\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Dec/2022 11:44:26] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0.99999917]]\n",
      "[{'intent': 'Appointment', 'probability': '0.99999917'}]\n",
      "Appointment\n",
      "Answer:  Please send us an email at gradanalaytics@georgetown.edu\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "is there any upcoming information session/webinar\n",
      "1/1 [==============================] - 0s 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [05/Dec/2022 11:44:40] \"POST /get HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 0.88173425]]\n",
      "[{'intent': 'information_session', 'probability': '0.88173425'}]\n",
      "information_session\n",
      "Answer:  The Information Session generally takes place in October- November. Applicants can register for the same. Please email gradanalytics@georgetown.edu for the exam dates and signup sheet. You can view previous information session recordings and slides here: https://analytics.georgetown.edu/admissions/oh_webinars/\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from flask import Flask, render_template, request\n",
    "import nltk\n",
    "from keras.models import load_model\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "\n",
    "# chat initialization\n",
    "model = load_model(\"model_output/chatbot_model.h5\")\n",
    "intents = json.loads(open(\"data/intents.json\").read())\n",
    "words = pickle.load(open(\"model_output/words.pkl\", \"rb\"))\n",
    "classes = pickle.load(open(\"model_output/classes.pkl\", \"rb\"))\n",
    "\n",
    "app = Flask(__name__)\n",
    "# run_with_ngrok(app) \n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return render_template(\"index_v2.html\")\n",
    "\n",
    "\n",
    "@app.route(\"/get\", methods=[\"POST\"])\n",
    "def chatbot_response():\n",
    "    msg = request.form[\"msg\"].lower()\n",
    "    print(msg)\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res\n",
    "\n",
    "\n",
    "# chat functionalities\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=True):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words - matrix of N words, vocabulary matrix\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                # assign 1 if current word is in the vocabulary position\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(\"found in bag: %s\" % w)\n",
    "    return np.array(bag)\n",
    "\n",
    "\n",
    "def predict_class(sentence, model):\n",
    "    # filter out predictions below a threshold\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "   \n",
    "    ERROR_THRESHOLD = 0.5\n",
    "\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    #sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(results)\n",
    "    \n",
    "\n",
    "    confidence_probability=0.6\n",
    "    return_list = []\n",
    "\n",
    "    if len(results) == 0:\n",
    "        return_list.append({\"intent\": 'failed', \"probability\": '1'})\n",
    "    elif results[0][1] >=  confidence_probability:\n",
    "        return_list.append({\"intent\": classes[results[0][0]], \"probability\": str(results[0][1])})\n",
    "    else: \n",
    "        return_list.append({\"intent\": 'failed', \"probability\": '1'})\n",
    "   \n",
    "    print(return_list)\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0][\"intent\"]\n",
    "    print(tag)\n",
    "    \n",
    "    list_of_intents = intents_json[\"intents\"]\n",
    "\n",
    "    for i in list_of_intents:\n",
    "        if i[\"tag\"] == tag:\n",
    "            result = random.choice(i[\"responses\"])\n",
    "            break\n",
    "        else:\n",
    "            result= \"Sorry, I don't understand that. Please rephrase/ask another question or send an email to gradanalytics@georgetown.edu\"\n",
    "        \n",
    "    print(\"Answer: \", result)\n",
    "    print(\"-----------------------------------------------------------------------------------------------------\")\n",
    "    print(\"\\n\")\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(port='0000')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "170ce1dd6f4b41f87201bcaa71a63fa2dc3233be29ef0b52e1889288dbb460d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
